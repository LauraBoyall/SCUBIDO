---
title: "SCUBIDO"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{SCUBIDO}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

**S**imulating **C**limate **U**sing **B**ayesian **I**nference from proxy **D**ata **O**bservations![](images/SCUBIDO logo .png){width="0.71in" height="0.81in"}

This vignette is used to explain in greater detail the work flow of the `SCUBIDO` R package.

The aim of this package is to create a reconstruction of palaeoclimate given multivariate μXRF-CS data from lake sediments using Bayesian inference. More detaols on the mathematics behind the model can be found in Boyall et al (in prep).

It is vital that each of the **3** functions are used for this package otherwise the package will fail. Therefore this vignette walks you each function.

### Introduction

The first thing to do it load in the `SCUBIDO` package. If `SCUBIDO` is not already installed then do so by loading the `devtools` package and then installing from Github.

```{r setup, message=FALSE,warning=FALSE}
devtools::install_github("LauraBoyall/SCUBIDO") # if not previously installed
library(SCUBIDO)
```

## Loading in your data

The `SCUBIDO` package requires two datasets, the first being some modern data `modern_data` with the most recent part of the μXRF-CS data which has an overlap with some instrumental climate data. For example it may be a section from 1950 to present. It is important for this data set that the age (**in cal BP**) is in the first column, the climate data is in the second and then the remaining columns are the individual elements. We recommend here that your μXRF-CS data is central-log ratio transformed.

Please not that your climate variable must **be in anomalies** as we use a grid of -3 to +3°C for the model to pick values from. This current version of `SCUBIDO` does not currently have an approach to reconstruct beyond these temperatures using the package functions. If users are reconstructing climate and believe that the values are going to be greater than this range then we refer them to the R file in the GitHub repository to change the grid manually.

An example of the structure data set is displayed below using a fake data set:

```{r message=FALSE,warning=FALSE, echo = FALSE}


# Set seed for reproducibility
set.seed(123)

# Define number of rows for the fake data
n <- 100

# Create Age BP column (starting from 1990 CE, transformed to Age BP)
# Age BP = 1950 - Year CE
age_ce <- seq(1990, 1990 - (n - 1), by = -1)
age_bp <- 1950 - age_ce

# Set a baseline temperature (e.g., 15 degrees Celsius) and create random anomalies
baseline_temp <- 15  # baseline temperature
temperature_anomalies <- rnorm(n, mean = 0, sd = 0.5)  # anomalies around 0, with small variations

# Create random XRF data (example range for each element)
S <- round(runif(n, min = 0, max = 1000))
Si <- round(runif(n, min = 0, max = 1000))
K <- round(runif(n, min = 0, max = 1000))
Ca <- round(runif(n, min = 0, max = 1000))
Ti <- round(runif(n, min = 0, max = 1000))
M <- round(runif(n, min = 0, max = 1000))
V <- round(runif(n, min = 0, max = 1000))
Rb <- round(runif(n, min = 0, max = 1000))
Sr <- round(runif(n, min = 0, max = 1000))

# Combine into a data frame
fake_data <- data.frame(
  Age_BP = age_bp,
  Temperature_Anomaly = temperature_anomalies,
  S = S,
  Si = Si,
  K = K,
  Ca = Ca,
  Ti = Ti,
  M = M,
  V = V,
  Rb = Rb,
  Sr = Sr
)

# Show the first few rows of the data
print(head(fake_data),row.names = F)



```

The second data set required is the `fossil_data`. This data is the remainder of your μXRF-CS data and follows the same structure as the modern but the second column which held the climate value is not there. Therefore you should have one less column in your table. Example below:

```{r message=FALSE,warning=FALSE, echo = FALSE}
# Set seed for reproducibility
set.seed(123)

# Define number of rows for the fake data
n <- 100

# Generate random decimal increments (e.g., between 0.1 and 1 year)
age_increments <- runif(n, min = 0.1, max = 1)

# Create Age BP column starting from 291 BP, using cumulative sum of the increments
age_bp <- 291 + cumsum(age_increments)

# Create random XRF data (example range for each element, rounded)
S <- round(runif(n, min = 0, max = 1000))
Si <- round(runif(n, min = 0, max = 1000))
K <- round(runif(n, min = 0, max = 1000))
Ca <- round(runif(n, min = 0, max = 1000))
Ti <- round(runif(n, min = 0, max = 1000))
M <- round(runif(n, min = 0, max = 1000))
V <- round(runif(n, min = 0, max = 1000))
Rb <- round(runif(n, min = 0, max = 1000))
Sr <- round(runif(n, min = 0, max = 1000))

# Combine into a data frame
fake_data <- data.frame(
  Age_BP = age_bp,
  S = S,
  Si = Si,
  K = K,
  Ca = Ca,
  Ti = Ti,
  M = M,
  V = V,
  Rb = Rb,
  Sr = Sr
)

# Show the first few rows of the data without row numbers
print(head(fake_data), row.names = FALSE)

```

Once the data is set up we can begin by using the `SCUBIDO` package!

## SCUBIDO_input

The `SCUBDIO_input` function is used to sort your data and split create a data list to be used later in the model. It is important that you save the outputs of the function as shown below as these are needed in the following function.

the summary print out shows what is saved within the sorted list. This function also re-scales the μXRF-CS data and creates a few time files which help with later application.

```{r, message=FALSE,warning=FALSE}
sorted_data <- SCUBIDO_input(modern_data = modern_data, fossil_data = fossil_data)
summary(sorted_data)
```

## SCUBIDO_cal

Once the data has been sorted we can now begin to model the data! This first function involves the calibration modern data. Within this stage we learn about the relationship between the individual elements and climate, but also about the covariance between them.

Here we use the saved list from the `SCUBIDO_cal` function. Once this function has run it will save a model file to your working directory. This uses the system date to allow the script to load previous models. If you would like to upload the model on another day then you should go to the saved file and change the date in the file name as the function will otherwise re-start the model and save with today's date.

```{r model-calibration, echo=TRUE, fig.width=8, fig.height=6}
# Show this code to the user (as if running it normally)
calibrated_data <- SCUBIDO_cal(sorted = sorted_data, plot = TRUE, summary = FALSE)

# Internally capture and suppress all other messages to prevent them from appearing in the output
invisible(capture.output(
  calibrated_data <- SCUBIDO_cal(sorted = sorted_data, plot = TRUE, summary = FALSE)
))


```

Here we would like to ensure that the model has fully converged and a simple way of checking this is through looking at the R-hat values. You can read more about what R-hat values mean by checking out Gelman and Rubin (1992) and Brooks and Gelman (1998). However in summary your R-hat values should be \<1.05. You can find this on the print out after this code has run on the far left side of the table if you choose `summary = TRUE`.

If you choose to also do `plot = TRUE` then you will get a series of graphs showing the quadratic relationship between the XRF elements and the climate time series. All of the outputs for this will be stored in your calibrated file, for our example it will be stored in `calibrated_data` and the `sims.list` list stored inside this will have all of the model outputs if you would like to plot differently / explore the model and then the `sorted` list stored in the `calibrated_data` contains the data from the previous function.

## SCUBIDO_reconstruct

The final function in SCUBIDO is `SCUBIDO_reconstruct` and this will produce the final reconstruction of quantitative climate given μXRF-CS data. Like usual we we load in the previous function's file (`calibrated_data`).

**Note that this function does take a long time, it will ask you if you wish to continue but please be aware that for thousands of date layers (rows in your xrf data) then it is possible that it could take up to 24 hours (why not run it over the weekend!). This is based on running it on a single core so if you can use parallel cores then use this.**

```{r reconstruct, echo=TRUE, fig.width=8, fig.height=6}
# Show this line to users
reconstruction <- SCUBIDO_reconstruct(calibration_data = calibrated_data, plot_graph = TRUE)

# Suppress the unwanted messages, but do not show this part to users
invisible(capture.output(
  reconstruction <- SCUBIDO_reconstruct(calibration_data = calibrated_data, plot_graph = TRUE)
))

```

Whilst this is the default plot the function produces, you can easily extract the resulting data frame and plot in whichever way you wish.

```{r}
final <- reconstruction$reconstruction # note that we have saved our reconstruction as 'reconstruction' however you may have chosen a different name!

# write.csv(final, "Final Climate Reconstruction.csv)

```

And there you have it! By this point you would have been able to reconstruct annual climate given μXRF-CS data! If you have any queries please contact Laura Boyall at Laura.boyall.2016\@live.rhul.ac.uk

You must cite the original publication (Boyall et al., in prep) if you use this package to publish any work.

***Happy modelling!!***
